{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f914fc1",
   "metadata": {},
   "source": [
    "# Runs through the nuScenes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed113b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avapi.nuscenes import nuScenesManager\n",
    "\n",
    "\n",
    "# initialize scene manager\n",
    "nusc_data_dir = \"../../data/nuScenes\"\n",
    "NSM = nuScenesManager(nusc_data_dir, split=\"v1.0-mini\")  # v1.0-trainval for full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8c780",
   "metadata": {},
   "source": [
    "## Loops over nuscenes, applies perception and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avstack.modules.assignment import build_A_from_iou, gnn_single_frame_assign\n",
    "\n",
    "\n",
    "def compute_assignment_metrics(observed, truth):\n",
    "    \"\"\"Compute the metrics between a set of objects and truths\"\"\"\n",
    "\n",
    "    # perform assignment\n",
    "    A = build_A_from_iou(observed, truth)\n",
    "    assign = gnn_single_frame_assign(A, algorithm=\"JVC\", cost_threshold=-0.10)\n",
    "    iou_assign = [-A[a[0], a[1]] for a in assign.assignment_tuples]\n",
    "\n",
    "    # package up the metrics\n",
    "    metrics = {\n",
    "        \"n_observed\": len(observed),\n",
    "        \"n_truth\": len(truth),\n",
    "        \"n_assignment\": len(assign.assignment_tuples),\n",
    "        \"iou_of_assign\": iou_assign,\n",
    "        \"n_fp\": len(observed) - len(assign.assignment_tuples),\n",
    "        \"n_fn\": len(truth) - len(assign.assignment_tuples),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avstack.modules.perception.object2dfv import MMDetObjectDetector2D\n",
    "from avstack.modules.perception.object3d import MMDetObjectDetector3D\n",
    "\n",
    "# set up the perception here (always the same)\n",
    "# -- 2d detection from images\n",
    "print(\"Loading image perception model\")\n",
    "detector_2d = MMDetObjectDetector2D(\n",
    "    model=\"fasterrcnn\",\n",
    "    dataset=\"nuscenes\",\n",
    "    threshold=0.5,\n",
    "    gpu=0,\n",
    "    epoch=\"latest\",\n",
    ")\n",
    "# -- 3d detection from lidar\n",
    "print(\"Loading lidar perception model\")\n",
    "detector_3d = MMDetObjectDetector3D(\n",
    "    model=\"pointpillars\",\n",
    "    dataset=\"nuscenes\",\n",
    "    threshold=0.5,\n",
    "    gpu=0,\n",
    "    epoch=\"latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ce4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avapi.visualize.snapshot import show_image_with_boxes, show_lidar_bev_with_boxes\n",
    "\n",
    "\n",
    "# test out 2d and 3d detectors\n",
    "NSD = NSM.get_scene_dataset_by_index(0)\n",
    "frame_idx = 10\n",
    "camera = \"CAM_FRONT\"\n",
    "lidar = \"LIDAR_TOP\"\n",
    "frame = NSD.get_frames(sensor=camera)[frame_idx]\n",
    "img = NSD.get_image(frame=frame, sensor=camera)\n",
    "pc = NSD.get_lidar(frame=frame, sensor=lidar)\n",
    "\n",
    "# run inference\n",
    "dets_2d = detector_2d(img)\n",
    "dets_3d = detector_3d(pc)\n",
    "\n",
    "# visualize results\n",
    "show_image_with_boxes(img, boxes=dets_2d, inline=True, show=True)\n",
    "show_lidar_bev_with_boxes(pc, boxes=dets_3d, inline=True, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd447c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from avstack.geometry import GlobalOrigin3D\n",
    "from avstack.modules.tracking.tracker2d import BasicBoxTracker2D\n",
    "from avstack.modules.tracking.tracker3d import BasicBoxTracker3D\n",
    "\n",
    "\n",
    "\n",
    "# loop over scenes\n",
    "metrics_scenes = {}\n",
    "for scene in NSM.scenes:\n",
    "    # get this scene (dataset)\n",
    "    print(f\"Running over scene: {scene}\")\n",
    "    NSD = NSM.get_scene_dataset_by_name(scene)\n",
    "\n",
    "    # initialize new trackers\n",
    "    # -- 2d box tracker\n",
    "    tracker_2d = BasicBoxTracker2D(\n",
    "        threshold_confirmed=2,\n",
    "        threshold_coast=5,\n",
    "        v_max=200,\n",
    "        cost_threshold=-0.1,\n",
    "        check_reference=False,  # don't check ref for 2D tracks\n",
    "    )\n",
    "    # -- 3d box tracker\n",
    "    tracker_3d = BasicBoxTracker3D(\n",
    "        threshold_confirmed=3,\n",
    "        threshold_coast=5,\n",
    "        v_max=60,\n",
    "        assign_metric=\"center_dist\",\n",
    "        assign_radius=6,\n",
    "        check_reference=True,\n",
    "    )\n",
    "    \n",
    "    # run through the frames\n",
    "    all_sensors = NSD.sensor_IDs\n",
    "    camera = \"CAM_FRONT\"  # could also use another sensor from \"all_sensors\"\n",
    "    lidar = \"LIDAR_TOP\"\n",
    "    metrics_frames = {}\n",
    "    for frame in tqdm(NSD.get_frames(sensor=camera)):\n",
    "        # get sensor data\n",
    "        ts = NSD.get_timestamp(frame=frame, sensor=camera)\n",
    "        img = NSD.get_image(frame=frame, sensor=camera)\n",
    "        pc = NSD.get_lidar(frame=frame, sensor=lidar)\n",
    "\n",
    "        # run perception in the LOCAL coordinates\n",
    "        dets_2d = detector_2d(img)\n",
    "        dets_3d = detector_3d(pc)\n",
    "\n",
    "        # run tracking in the GLOBAL coordinates\n",
    "        tracks_2d = tracker_2d(dets_2d, platform=GlobalOrigin3D)\n",
    "        tracks_3d = tracker_3d(dets_3d, platform=GlobalOrigin3D)\n",
    "\n",
    "        # get truth locations for metrics\n",
    "        objs_cam = NSD.get_objects(frame=frame, sensor=camera, max_dist=60)\n",
    "        objs_lid = NSD.get_objects(frame=frame, sensor=lidar, max_dist=60)\n",
    "\n",
    "        # compute metrics for each frame\n",
    "        metrics_2d_det = compute_assignment_metrics(dets_2d, objs_cam)\n",
    "        metrics_3d_det = compute_assignment_metrics(dets_3d, objs_lid)\n",
    "        metrics_2d_trk = compute_assignment_metrics(tracks_2d, objs_cam)\n",
    "        metrics_3d_trk = compute_assignment_metrics(tracks_3d, objs_lid)\n",
    "\n",
    "        # store metrics\n",
    "        metrics_frames[frame] = {\n",
    "            \"scene\": scene,\n",
    "            \"frame\": frame,\n",
    "            \"timestamp\": ts,\n",
    "            \"perception\": [\n",
    "                {\n",
    "                    \"sensor\": camera,\n",
    "                    \"metrics\": metrics_2d_det,\n",
    "                },\n",
    "                {\n",
    "                    \"sensor\": lidar,\n",
    "                    \"metrics\": metrics_3d_det,\n",
    "                },\n",
    "            ],\n",
    "            \"tracking\": [\n",
    "                {\n",
    "                    \"sensor\": camera,\n",
    "                    \"metrics\": metrics_2d_trk,\n",
    "                },\n",
    "                {\n",
    "                    \"sensor\": lidar,\n",
    "                    \"metrics\": metrics_3d_trk,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # NOTE: to continue to run through all the scenarios, don't include this break\n",
    "        if frame > 10:\n",
    "            break\n",
    "\n",
    "    # visualize the last set of data\n",
    "    show_image_with_boxes(img, boxes=dets_2d, inline=True, show=True)\n",
    "    show_image_with_boxes(img, boxes=tracks_2d, inline=True, show=True)\n",
    "    show_lidar_bev_with_boxes(pc, boxes=dets_3d, inline=True, show=True)\n",
    "    show_lidar_bev_with_boxes(pc, boxes=tracks_3d, inline=True, show=True)\n",
    "\n",
    "    # store the metrics for this scene\n",
    "    metrics_scenes[scene] = metrics_frames\n",
    "\n",
    "    # NOTE: to continue to run through all the scenarios, don't include this break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aae164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
